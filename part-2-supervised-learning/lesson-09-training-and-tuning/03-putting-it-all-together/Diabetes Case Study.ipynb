{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes Case Study\n",
    "\n",
    "You now have had the opportunity to work with a range of supervised machine learning techniques for both classification and regression.  Before you apply these in the project, let's do one more example to see how the machine learning process works from beginning to end with another popular dataset.\n",
    "\n",
    "We will start out by reading in the dataset and our necessary libraries.  You will then gain an understanding of how to optimize a number of models using grid searching as you work through the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import check_file as ch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in our dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Take a look at the first few rows of the dataset\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this course has been aimed at understanding machine learning techniques, we have largely ignored items related to parts of the data analysis process that come before building machine learning models - exploratory data analysis, feature engineering, data cleaning, and data wrangling.  \n",
    "\n",
    "> **Step 1:** Let's do a few steps here.  Take a look at some of usual summary statistics calculated to accurately match the values to the appropriate key in the dictionary below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Cells for work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Awesome! These all look great!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Possible keys for the dictionary\n",
    "a = '0.65'\n",
    "b = '0'\n",
    "c = 'Age'\n",
    "d = '0.35'\n",
    "e = 'Glucose'\n",
    "f = '0.5'\n",
    "g = \"More than zero\"\n",
    "\n",
    "# TODO - DONE\n",
    "# Fill in the dictionary with the correct values here\n",
    "answers_one = {\n",
    "    'The proportion of diabetes outcomes in the dataset': d,\n",
    "    'The number of missing data points in the dataset': b,\n",
    "    'A dataset with a symmetric distribution': e,\n",
    "    'A dataset with a right-skewed distribution': c, \n",
    "    'This variable has the strongest correlation with the outcome': e\n",
    "}\n",
    "\n",
    "# Just to check your answer, don't change this\n",
    "ch.check_one(answers_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 2**: Since our dataset here is quite clean, we will jump straight into the machine learning.  Our goal here is to be able to predict cases of diabetes.  First, you need to identify the y vector and X matrix.  Then, the following code will divide your dataset into training and test data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO - DONE\n",
    "X = diabetes.iloc[:, :-1]\n",
    "y = diabetes.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a training and testing dataset, we need to create some models that and ultimately find the best of them.  However, unlike in earlier lessons, where we used the defaults, we can now tune these models to be the very best models they can be.\n",
    "\n",
    "It can often be difficult (and extremely time consuming) to test all the possible hyperparameter combinations to find the best models.  Therefore, it is often useful to set up a randomized search.  \n",
    "\n",
    "In practice, randomized searches across hyperparameters have shown to be more time confusing, while still optimizing quite well.  One article related to this topic is available [here](https://blog.h2o.ai/2016/06/hyperparameter-optimization-in-h2o-grid-search-random-search-and-the-future/).  The documentation for using randomized search in sklearn can be found [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py) and [here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "In order to use the randomized search effectively, you will want to have a pretty reasonable understanding of the distributions that best give a sense of your hyperparameters.  Understanding what values are possible for your hyperparameters will allow you to write a grid search that performs well (and doesn't break).\n",
    "\n",
    "> **Step 3**: In this step, I will show you how to use randomized search, and then you can set up grid searches for the other models in Step 4.  However, you will be helping, as I don't remember exactly what each of the hyperparameters in SVMs do.  Match each hyperparameter to its corresponding tuning functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Accuracy score for random forest : 0.7532467532467533\nPrecision score random forest : 0.6545454545454545\nRecall score random forest : 0.6545454545454545\nF1 score random forest : 0.6545454545454545\n\n\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# build a classifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# Set up the hyperparameter search\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"n_estimators\": list(range(10, 200)),\n",
    "              \"max_features\": list(range(1, X_test.shape[1]+1)),\n",
    "              \"min_samples_split\": list(range(2, 11)),\n",
    "              \"min_samples_leaf\": list(range(1, 11)),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "# Run a randomized search over the hyperparameters\n",
    "random_search_rf = RandomizedSearchCV(clf_rf, param_distributions=param_dist)\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "rf_preds = random_search_rf.best_estimator_.predict(X_test)\n",
    "\n",
    "ch.print_metrics(y_test, rf_preds, 'random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 4**: Now that you have seen how to run a randomized grid search using random forest, try this out for the AdaBoost and SVC classifiers.  You might also decide to try out other classifiers that you saw earlier in the lesson to see what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Accuracy score for adaboost : 0.7727272727272727\nPrecision score adaboost : 0.6923076923076923\nRecall score adaboost : 0.6545454545454545\nF1 score adaboost : 0.6728971962616823\n\n\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO - DONE\n",
    "\n",
    "# build a classifier for ada boost\n",
    "clf_ab = AdaBoostClassifier()\n",
    "\n",
    "# Set up the hyperparameter search\n",
    "# look at  setting up your search for n_estimators, learning_rate\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "param_dist = {\"n_estimators\": [10, 100, 200, 400],\n",
    "              \"learning_rate\": [0.001, 0.005, .01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 10, 20]}\n",
    "\n",
    "# Run a randomized search over the hyperparameters\n",
    "random_search = RandomizedSearchCV(clf_ab, param_distributions=param_dist)\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "ada_preds = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Return your metrics on test data\n",
    "ch.print_metrics(y_test, ada_preds, 'adaboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n",
      "E:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\nE:\\programs\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Accuracy score for svc : 0.7532467532467533\nPrecision score svc : 0.6545454545454545\nRecall score svc : 0.6545454545454545\nF1 score svc : 0.6545454545454545\n\n\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# build a classifier for support vector machines\n",
    "clf_svm = SVC()\n",
    "\n",
    "# Set up the hyperparameter search\n",
    "# look at setting up your search for C (recommend 0-10 range), \n",
    "# kernel, and degree\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "param_dist = {\"C\": [0.1, 0.5, 1, 3, 5],\n",
    "              \"kernel\": ['linear','rbf']\n",
    "             }\n",
    "\n",
    "\n",
    "# Run a randomized search over the hyperparameters\n",
    "random_search = RandomizedSearchCV(clf_svm, param_distributions=param_dist)\n",
    "\n",
    "# Fit the model on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "svc_preds = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "\n",
    "# Return your metrics on test data\n",
    "ch.print_metrics(y_test, svc_preds, 'svc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 5**: Use the test below to see if your best model matched, what we found after running the grid search.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Nice!  It looks like your best model matches the best model I found as well!  It makes sense to use f1 score to determine best in this case given the imbalance of classes.  There might be justification for precision or recall being the best metric to use as well - precision showed to be best with adaboost again.  With recall, SVMs proved to be the best for our models.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = 'randomforest'\n",
    "b = 'adaboost'\n",
    "c = 'supportvector'\n",
    "\n",
    "# TODO\n",
    "best_model =  b\n",
    "\n",
    "# See if your best model was also mine.  \n",
    "# Notice these might not match depending your search!\n",
    "ch.check_best(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have found your best model, it is also important to understand why it is performing well.  In regression models where you can see the weights, it can be much easier to interpret results. \n",
    "\n",
    "> **Step 6**:  Despite the fact that your models here are more difficult to interpret, there are some ways to get an idea of which features are important.  Using the \"best model\" from the previous question, find the features that were most important in helping determine if an individual would have diabetes or not. Do your conclusions match what you might have expected during the exploratory phase of this notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO - COPIED FROM SOLUTION\n",
    "# Show your work here - the plot below was helpful for me\n",
    "# https://stackoverflow.com/questions/44101458/random-forest-feature-importance-chart-using-python\n",
    "\n",
    "features = diabetes.columns[:diabetes.shape[1]]\n",
    "importances = random_search_rf.best_estimator_.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), features[indices])\n",
    "plt.xlabel('Relative Importance');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 7**:  Using your results above to complete the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "That's right!  Some of these were expected, but some were a bit unexpected too!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Check your solution by matching the correct values in the dictionary\n",
    "# and running this cell\n",
    "a = 'Age'\n",
    "b = 'BloodPressure'\n",
    "c = 'BMI'\n",
    "d = 'DiabetesPedigreeFunction'\n",
    "e = 'Insulin'\n",
    "f = 'Glucose'\n",
    "g = 'Pregnancy'\n",
    "h = 'SkinThickness'\n",
    "\n",
    "# TODO\n",
    "sol_seven = {\n",
    "    'The variable that is most related to the outcome of diabetes' : f,\n",
    "    'The second most related variable to the outcome of diabetes' : c,\n",
    "    'The third most related variable to the outcome of diabetes' : a,\n",
    "    'The fourth most related variable to the outcome of diabetes' : d\n",
    "}\n",
    "\n",
    "ch.check_q_seven(sol_seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 8**:  Now provide a summary of what you did through this notebook, and how you might explain the results to a non-technical individual.  When you are done, check out the solution notebook by clicking the orange icon in the upper left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}